---
title: "Lab session-3"
author: "Necati Ertekin"
output: word_document
editor_options: 
  chunk_output_type: console
---

#==========================================================
## SET UP R MARKDOWN
#==========================================================
```{r}
# You should generally clear the working space at the start of every R session
rm(list = ls())

# Set the directory
setwd("C:/Users/tpstech/Desktop/BA SCU/OMIS 2392 Econometrics with R/Lab Sessions")

# install packages
#install.packages("ggeffects")
#install.packages("QuantPsyc")
install.packages("VIF")
#install.packages("usdm")
#install.packages("lmtest")
#install.packages("multiwayvcov")
#install.packages("sandwich")
#install.packages("AER")
#install.packages("aod")
#install.packages("mfx")


# Load libraries everytime you start a session
library(stargazer)
library(gdata)
library(ggplot2)
library(psych) 
library(ggeffects)
library(QuantPsyc)
library(usdm)
library(lmtest)
library(multiwayvcov)
library(sandwich)
library(foreign)
library(AER)
library(aod)
library(Rcpp)
library(mfx)
library(nnet)
library(reshape2)
library(VIF)
library(MASS)

# turn off scientific notation except for big numbers. 
options(scipen = 9)
```

#==========================================================
## LOAD AND EXPLORE DATA
#==========================================================
```{r}
mydata = read.csv("KaysJewelers.csv")

# Summary statistics
stargazer(mydata, type="text", median=TRUE, iqr=TRUE,digits=1, title="Descriptive Statistics")  # basic descriptive statistics

ggplot(mydata, aes(x=price)) + geom_histogram(colour="green") # we will use the original variable
ggplot(mydata, aes(x=log(price))) + geom_histogram(colour="green") # we will use the original variable

ggplot(mydata, aes(x=pastpurchase)) + geom_histogram(colour="green") # we will use the original variable
ggplot(mydata, aes(x=log(1+pastpurchase))) + geom_histogram(colour="green") 

# research question: the impact of the difference between perceived quality and actual quality
# dependent variable: return 
# key IV: TWO! 1. survey 2. 1- reject rate(objective quality) 
# CV: price(higher price, higher return rate), gender(consumer geomagraphic should be considiered), income(lower income higher return rate), age, baseketsize 
# Model: logit or probit, any of them
```

#==========================================================
## MODEL DEVELOPMENT
#==========================================================
```{r}
# Check Multicollineary

mydata$objectivequal=1-mydata$rejectrate
mydata$perceivedqual = mydata$survey4
mydata$female = ifelse(mydata$gender=="F",1,0)

df <- data.frame(mydata$perceivedqual,mydata$objectivequal,mydata$price,mydata$basketsize,mydata$pastpurchase,mydata$pastreturn,mydata$holiday,mydata$age,mydata$female,mydata$income )  # no depdent variable 
cor(df) # Generates the correlation matrix
vifcor(df) #  VIF scores are less than 3, no indication of multicollinearity

# Initial model...

probit1<- glm(return~perceivedqual+objectivequal+price+basketsize+pastpurchase+pastreturn+holiday+age+female+ income + factor(malltype), data=mydata, family=binomial(link="probit"))  

stargazer(probit1,
          title="Regression Results", type="text", 
          column.labels=c("Probit-1"),
          df=FALSE, digits=3, star.cutoffs = c(0.05,0.01,0.001)) #  objective quality is not significant and perceived quality is significant and as expected  
# as customer thinks the quality is high, the return will be less. It is sigficant, the theroy holds 

## Model fit assessment 
probit1a <- glm(return~1, data=mydata, family=binomial(link="probit")) # This is the command to run a probit on null model 
lrtest(probit1, probit1a) #We compare the null model to our model to determine the model fit. The p-value for the chi-square tet is  less than 0.001. Thus, our model fits significantly better than the null model.

## Measuring the predictive power of the probit
pred = predict(probit1, data=mydata, type="response")  # in sample prediction, without type = "response", it will predicted Z scores, we want predicted probabilities. 
head(pred)
return_prediction <- ifelse(pred >= 0.5,1,0)  
misClasificError <- mean(return_prediction != mydata$return) 
print(paste('Accuracy',1-misClasificError)) # the correct classification rate is 85.64%, which is quite good
# greater than the threshold, 80%. 

# Check for heteroscedasticity
gqtest(probit1) # Significant Goldfeld-Quandt test does not indicate heteroscedasticity 
bptest(probit1) # Significant Breusch-Pagan test indicates heteroscedasticity

HWrobstder <- sqrt(diag(vcovHC(probit1, type="HC1"))) # produces Huber-White robust standard errors 

stargazer(probit1, probit1,  
          se=list(NULL, HWrobstder),
          title="Regression Results", type="text", 
          column.labels=c("Normal SE", "HW-Robust SE"),
          df=FALSE, digits=3, star.cutoffs = c(0.05,0.01,0.001))  # displays normal/HW robust  standard errors. objective quality is not significant and perceived quality is significant and as expected

## Adding Seasonality...
Aggregate_data <- aggregate(mydata[c("return")], by=list(mydata$month), mean) 
ggplot(Aggregate_data, aes(x=Group.1, y=return)) + geom_line() + geom_point(size=3, colour="maroon") + 
  xlab("Month") + ylab("Return rate") # It seems there is monthly seasonal effect on returns
## aggregate function generated a dataset of 12 observations with 2 columns, first column is Group.1 -- 1-12, second column is return

Aggregate_data <- aggregate(mydata[c("return")], by=list(mydata$year), mean) 
ggplot(Aggregate_data, aes(x=Group.1, y=return)) + geom_line() + geom_point(size=3, colour="maroon") + 
  xlab("Year") + ylab("Return rate") # It seems there is annual seasonal effect on returns
## 4 obsercations with 2 columns

probit2<- glm(return~perceivedqual+objectivequal+price+basketsize+pastpurchase+pastreturn+holiday+age+female+ income + factor(malltype) + factor(month) + factor(year), data=mydata, family=binomial(link="probit"))  

probit2a <- glm(return~1, data=mydata, family=binomial(link="probit")) # This is the command to run a logit on null model 
lrtest(probit2, probit2a) #We compare the null model to our model to determine the model fit. The p-value for the chi-square tet is  less than 0.001. Thus, model probit-2 fits significantly better than the null model.

stargazer(probit1, probit2,
          title="Regression Results", type="text", 
          column.labels=c("Probit-1", "Probit-2"),
          df=FALSE, digits=2, star.cutoffs = c(0.05,0.01,0.001)) #  objective quality is not significant and perceived quality is significant and as expected 

anova(probit1, probit2, test="Chisq") # It shows that seasonality variables improve model fit significantly

# Check for heteroscedasticity
gqtest(probit2) # Significant Goldfeld-Quandt test does not indicate heteroscedasticity 
bptest(probit2) # Significant Breusch-Pagan test indicates heteroscedasticity

HWrobstder <- sqrt(diag(vcovHC(probit2, type="HC1"))) # produces Huber-White robust standard errors 

stargazer(probit2, probit2,  
          se=list(NULL, HWrobstder),
          title="Regression Results", type="text", 
          column.labels=c("Normal SE", "HW-Robust SE"),
          df=FALSE, digits=3, star.cutoffs = c(0.05,0.01,0.001))  # displays normal/HW robust  standard errors. objective quality is not significant and perceived quality is significant and as expected

pred = predict(probit2, data=mydata, type="response") 
return_prediction <- ifelse(pred >= 0.5,1,0)  
misClasificError <- mean(return_prediction != mydata$return) 
print(paste('Accuracy',1-misClasificError)) # the correct classification rate increased to 85.74%


# Reoperationalize perceived quality...
mydata$perceivedqual2 <- mydata$perceivedqual * mydata$price

probit3<- glm(return~perceivedqual2+objectivequal+price+basketsize+pastpurchase+pastreturn+holiday+age+female+ income + factor(malltype) + factor(month) + factor(year), data=mydata, family=binomial(link="probit"))  

probit3a <- glm(return~1, data=mydata, family=binomial(link="probit")) # This is the command to run a logit on null model 
lrtest(probit3, probit3a) #We compare the null model to our model to determine the model fit. The p-value for the chi-square tet is  less than 0.001. Thus, model probit-3 fits significantly better than the null model.

stargazer(probit2, probit3,
          title="Regression Results", type="text", 
          column.labels=c("Probit-2", "Probit-3"),
          df=FALSE, digits=2, star.cutoffs = c(0.05,0.01,0.001)) #  objective quality is not significant and perceived quality is significant and as expected 

AIC(probit2, probit3) # It shows that our initial operationalization of perceived quality is better 
BIC(probit2, probit3) 

pred = predict(probit3, data=mydata, type="response") 
return_prediction <- ifelse(pred >= 0.5,1,0)  
misClasificError <- mean(return_prediction != mydata$return) 
print(paste('Accuracy',1-misClasificError)) # the correct classification rate decreases to 85.38%. 
```

#==========================================================
## MODIFY TO THE CONCEPTUAL MODEL
#==========================================================
```{r}
# The salesperson impact

mydata$competence <- (mydata$survey1 + mydata$survey2 + mydata$survey3)/3

probit4<- glm(return~perceivedqual+objectivequal+competence+price+basketsize+pastpurchase+pastreturn+holiday+age+female+ income + factor(malltype) + factor(month) + factor(year), data=mydata, family=binomial(link="probit"))  

probit4a <- glm(return~1, data=mydata, family=binomial(link="probit")) # This is the command to run a logit on null model 
lrtest(probit4, probit4a) #We compare the null model to our model to determine the model fit. The p-value for the chi-square test is  less than 0.001. Thus, model probit-4 fits significantly better than the null model.

stargazer(probit2, probit4,
          title="Regression Results", type="text", 
          column.labels=c("Probit-2", "Probit-4"),
          df=FALSE, digits=2, star.cutoffs = c(0.05,0.01,0.001)) # Objective quality is not significant, yet competence is significant and as expected 

anova(probit2, probit4, test="Chisq") # It shows that competence significantly improves model fit

gqtest(probit4) # Significant Goldfeld-Quandt test does not indicate heteroscedasticity 
bptest(probit4) # Significant Breusch-Pagan test indicates heteroscedasticity

HWrobstder <- sqrt(diag(vcovHC(probit4, type="HC1"))) # produces Huber-White robust standard errors 

stargazer(probit4, probit4,  
          se=list(NULL, HWrobstder),
          title="Regression Results", type="text", 
          column.labels=c("Normal SE", "HW-Robust SE"),
          df=FALSE, digits=3, star.cutoffs = c(0.05,0.01,0.001))  # displays normal/HW robust  standard errors. objective quality is not significant and perceived quality is significant and as expected

pred = predict(probit4, data=mydata,type="response") 
return_prediction <- ifelse(pred >= 0.5,1,0)  
misClasificError <- mean(return_prediction != mydata$return) 
print(paste('Accuracy',1-misClasificError)) # the correct classification rate increased to 91.12%

# The interaction between perceived quality and salesperson competence...

probit5<- glm(return~perceivedqual*competence+objectivequal+price+basketsize+pastpurchase+pastreturn+holiday+age+female+ income + factor(malltype) + factor(month) + factor(year), data=mydata, family=binomial(link="probit"))  

probit5a <- glm(return~1, data=mydata, family=binomial(link="probit")) # This is the command to run a logit on null model 
lrtest(probit5, probit5a) #We compare the null model to our model to determine the model fit. The p-value for the chi-square test is  less than 0.001. Thus, model probit-5 fits significantly better than the null model.

stargazer(probit4, probit5,
          title="Regression Results", type="text", 
          column.labels=c("Probit-4", "Probit-5"),
          df=FALSE, digits=2, star.cutoffs = c(0.05,0.01,0.001)) # The interaction term is significant 
# as competency increase, the impact of quality on return probability will decrease. IT is significant, so the coefficient of perceivequal is not important any more. 

anova(probit4, probit5, test="Chisq") # It shows that the interaction term significantly improves model fit

gqtest(probit5) # Significant Goldfeld-Quandt test does not indicate heteroscedasticity 
bptest(probit5) # Significant Breusch-Pagan test indicates heteroscedasticity

HWrobstder <- sqrt(diag(vcovHC(probit5, type="HC1"))) # produces Huber-White robust standard errors 

stargazer(probit5, probit5,  
          se=list(NULL, HWrobstder),
          title="Regression Results", type="text", 
          column.labels=c("Normal SE", "HW-Robust SE"),
          df=FALSE, digits=3, star.cutoffs = c(0.05,0.01,0.001))  # displays normal/HW robust  standard errors. The interaction term is still significant

pred = predict(probit5, data=mydata,type="response") 
return_prediction <- ifelse(pred >= 0.5,1,0)  
misClasificError <- mean(return_prediction != mydata$return) 
print(paste('Accuracy',1-misClasificError)) # the correct classification rate increased to 91.97%


# The interaction between Objective quality and salesperson competence...

probit6<- glm(return~perceivedqual*competence+objectivequal*competence+price+basketsize+pastpurchase+pastreturn+holiday+age+female+ income + factor(malltype) + factor(month) + factor(year), data=mydata, family=binomial(link="probit"))  

probit6a <- glm(return~1, data=mydata, family=binomial(link="probit")) # This is the command to run a logit on null model 
lrtest(probit6, probit6a) #We compare the null model to our model to determine the model fit. The p-value for the chi-square test is  less than 0.001. Thus, model probit-6 fits significantly better than the null model.

stargazer(probit5, probit6,
          title="Regression Results", type="text", 
          column.labels=c("Probit-4", "Probit-5"),
          df=FALSE, digits=2, star.cutoffs = c(0.05,0.01,0.001)) # The second interaction term is alsosignificant 

# as competency increase, the impact of objective quality on return probability will decrease! 

anova(probit5, probit6, test="Chisq") # It shows that the second interaction term significantly improves model fit

gqtest(probit6) # Significant Goldfeld-Quandt test does not indicate heteroscedasticity 
bptest(probit6) # Significant Breusch-Pagan test indicates heteroscedasticity

HWrobstder <- sqrt(diag(vcovHC(probit6, type="HC1"))) # produces Huber-White robust standard errors 

stargazer(probit6, probit6,  
          se=list(NULL, HWrobstder),
          title="Regression Results", type="text", 
          column.labels=c("Normal SE", "HW-Robust SE"),
          df=FALSE, digits=3, star.cutoffs = c(0.05,0.01,0.001))  # displays normal/HW robust  standard errors. Both interaction terms are still significant

pred = predict(probit6, data=mydata,type="response") 
return_prediction <- ifelse(pred >= 0.5,1,0)  
misClasificError <- mean(return_prediction != mydata$return) 
print(paste('Accuracy',1-misClasificError)) # the correct classification rate increased to 91.91%
```

#==========================================================
## VISUALIZE RESULTS
#==========================================================
```{r}
## Restimate the final model with pre-defined factor variables. This step is necessary because ggpredict command does not accept an estimated model if it includes a factor variable defined as "factor(x)" in the command line.   

mydata$fmall <- as.factor(mydata$malltype)
mydata$fmonth <- as.factor(mydata$month)
mydata$fyear <- as.factor(mydata$year)

probit6b<- glm(return~perceivedqual*competence+objectivequal*competence+price+basketsize+pastpurchase+pastreturn+holiday+age+female+ income + fmall + fmonth + fyear, data=mydata, family=binomial(link="probit"))  

print(summary(mydata$competence))

meffects <- ggpredict(probit6b, terms=c("perceivedqual", "competence [2.33,3,3.667]")) # generates a tidy data frame at three different values of competence  

ggplot(meffects,aes(x, predicted, colour=group)) + geom_line(size=1.3) + 
    xlab("Perceived Quality") + ylab("Return Probability") +
    labs(colour="Competence") + 
    scale_colour_discrete(labels=c("Low", "Moderate", "High"))


meffects2 <- ggpredict(probit6b, terms=c("objectivequal", "competence [2.33,3,3.667]")) # generates a tidy data frame at three different values of competence  

ggplot(meffects2,aes(x, predicted, colour=group)) + geom_line(size=1.3) + 
    xlab("Objective Quality") + ylab("Return Probability") +
    labs(colour="Competence") + 
    scale_colour_discrete(labels=c("Low", "Moderate", "High"))

```
